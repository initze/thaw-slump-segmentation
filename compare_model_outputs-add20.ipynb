{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare model outputs of AICORE DL Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import datetime\n",
    "\n",
    "# workaround buggy autocomplete\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_props_from_config(config_file):\n",
    "    config = yaml.load(open(config_file), Loader=yaml.BaseLoader)\n",
    "    m = config['model']\n",
    "    try:\n",
    "        resume = config['resume'][1]\n",
    "    except:\n",
    "        resume = ''\n",
    "    return config, resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vals_from_dir(subdir):\n",
    "    basename = subdir.name\n",
    "    \n",
    "    df_tr = pd.read_csv(subdir / 'train.csv')\n",
    "    df_tr['basename'] = basename[:]\n",
    "    df_tr['type'] = 'train'\n",
    "    df_tr['region'] = basename.split('__')[2]\n",
    "    #df_list_tr.append(df_tr)\n",
    "    \n",
    "    \n",
    "    df_v = pd.read_csv(s / 'val.csv')\n",
    "    df_v['basename'] = basename[:]\n",
    "    df_v['type'] = 'val'\n",
    "    df_v['region'] = basename.split('__')[2]\n",
    "    #df_list_v.append(df_v)\n",
    "    \n",
    "    return df_tr, df_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to open dir in explorer to connect !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = Path(r'.\\logs')\n",
    "#LOGDIR = Path(r'L:\\initze\\aicore-uc2_augmentation\\logs')\n",
    "#SUB_REGEX = '*'\n",
    "SUB_REGEX = '*CV6*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirs = list(LOGDIR.glob(SUB_REGEX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading \n",
    "- add config reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_tr = []\n",
    "df_list_v = []\n",
    "for s in subdirs:\n",
    "    try:\n",
    "        df_tr, df_v = get_vals_from_dir(s)\n",
    "    except:\n",
    "        continue\n",
    "    config_file = s / 'config.yml'\n",
    "\n",
    "    config, resume = get_props_from_config(config_file)\n",
    "\n",
    "    for df in [df_tr, df_v]:\n",
    "        df['architecture'] = config['model']['architecture']\n",
    "        df['backbone'] = config['model']['encoder']\n",
    "        df['loss_function'] = config['loss_function']\n",
    "        df['a_b'] = df['architecture'] + '_' + df['backbone']\n",
    "        df['resume'] = resume\n",
    "        df['stack_height'] = int(config['model_args']['stack_height'])\n",
    "        df['timestamp'] = datetime.datetime.strptime(config['run_info']['timestamp'], '%Y-%m-%d_%H-%M-%S')\n",
    "        df['data_sources'] = df.apply(lambda x: config['data_sources'], axis=1)\n",
    "        df['PR_diff'] = df['Precision'] - df['Recall']\n",
    "    \n",
    "    df_list_tr.append(df_tr)\n",
    "    df_list_v.append(df_v)\n",
    "\n",
    "df_train = pd.concat(df_list_tr).reset_index()\n",
    "df_val = pd.concat(df_list_v).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make proper datatypes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter by date\n",
    "* only load runs later than March 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.datetime(2021,3,22)\n",
    "df_train = df_train[df_train.timestamp > date]\n",
    "df_val = df_val[df_val.timestamp > date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge resumed trainings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter\n",
    "1. remove incomplete\n",
    "2. remove stack_height = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_val.groupby('basename').count()\n",
    "bn = grouped[grouped.Epoch >= 20].index\n",
    "df_val = df_val[df_val['basename'].isin(bn)]\n",
    "df_train = df_train[df_train['basename'].isin(bn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_val[df_val.stack_height == 6]\n",
    "df_train = df_train[df_train.stack_height == 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(df_val, 'df_val_filtered_add20.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(df_train, 'df_train_filtered_add20.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
